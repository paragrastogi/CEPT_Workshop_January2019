{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> How I learned to stop worrying and love uncertainty </h1>\n",
    "\n",
    "An introductory workshop on quantifying uncertainty in building simulation.\n",
    "\n",
    "<b>author</b>: Parag Rastogi; <b>venue</b>: TU Delft, Delft, The Netherlands; <b>date</b>: 04 June, 2018.\n",
    "\n",
    "Run each module one-by-one by either using the <kbd>run cell</kbd> button above or pressing <kbd>Ctrl + Enter</kbd> when a cell is selected. Modules like this one are `Markdown` modules, which is a kind of text-encoding language. These will not produce an output - instead you will see formatted text in the cell when you run one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initialisation</h2>\n",
    "\n",
    "<ol>\n",
    "<li>If you haven't read the wiki, I suggest starting there: https://github.com/paragrastogi/SimAud_2018_Uncertainty/wiki . \n",
    "\n",
    "<li> Download a folder of weather data here: https://drive.google.com/drive/folders/15hyS_Rg-DMxu05FkoS_K-NfFdAozvgJK?usp=sharing . You will see two folders in there: `ddn` and `gen`. Place them in the top-level directory, i.e., at the same level as `lib`.\n",
    "\n",
    "</ol>\n",
    "\n",
    "Everything should work ok on a Mac, though I have only tested the exercises on Windows and Ubuntu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a couple of packages to display images in the notebook.\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Uncertainty in Building Simulation</h2>\n",
    "\n",
    "<h3>What is it?</h3>\n",
    "\n",
    "Building Performance Simulation is an estimate of the (thermal and electrical) energy performance of a building. Since the performance estimate relies on knowing many inputs, it is affected by lack of knowledge or randomness in these inputs. Thus, uncertainty can be separated into two types:\n",
    "\n",
    "<ol>\n",
    "    <li> Epistemic\n",
    "    <li> Aleatory\n",
    "</ol>\n",
    "            \n",
    "\n",
    "\n",
    "Using \"Building Performance Simulation (BPS)... designers can obtain reliable performance estimates by testing their designs under many plausible operating conditions, e.g., the weather and usage the building might experience in the future. These estimates can then be used to choose a design that could deliver high performance for the rest of its life... Unfortunately, multiple simulations are time-consuming... Standard averaging methods, such as the Monte Carlo method, typically require a large number of simulations to ensure the quality of the estimate (MacDonald  2002; Iaccarino 2008}. In a typical building-design problem where a designer might test hundreds of designs, such methods might require hundreds of hours to run and quickly become infeasible. A preferred practice is to simply use a single 'average' or 'typical' estimate of future conditions, which is much faster. The danger of such a procedure is that it might miss a harmful operating condition where the building performs poorly or even breaks down. To ensure the robustness of designs it is, therefore, better to test them under a wide variety of plausible operating conditions. So is it possible to reduce the computation time of BPS such that multiple simulations during the design process are feasible?\" (Rastogi, Khan, and Andersen 2018, <i>in review</i>)\n",
    "\n",
    "Yes it is feasible! With rapid-response regression model, which we call an 'emulator' (because it emulates the original, physics-based building performance simulation model). A regression model can be used to answer some questions about a building's response, such as in robust design.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import various standard modules.\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Get inline graphs .\n",
    "%matplotlib inline\n",
    "\n",
    "# Only useful for debugging, when you \n",
    "# need to reload external modules.\n",
    "from importlib import reload\n",
    "\n",
    "# Enable xkcd mode - if you're a nerd.\n",
    "# plt.xkcd()\n",
    "\n",
    "# Import a custom read-write function for weather files.\n",
    "import wfileio as wf\n",
    "\n",
    "# import small helpers I've written.\n",
    "import petites as petite\n",
    "\n",
    "# Import an awesome colour palette. Call it colours.\n",
    "import default_colours as colours\n",
    "\n",
    "# Set the random seed to a specific value so\n",
    "# the experiment is repeatable.\n",
    "# See https://en.wikipedia.org/wiki/Random_seed\n",
    "# for more information on what this means.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "ValueError                                Traceback (most recent call last)",
      "<ipython-input-3-393f3e107f29> in <module>()\n     30     gen.append(gen_temp)\n     31     \n---> 32 gen = pd.concat(gen)\n     33 \n     34 metadata['locdata'].append(locdata)\n",
      "C:\\Miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py in concat(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, sort, copy)\n    223                        keys=keys, levels=levels, names=names,\n    224                        verify_integrity=verify_integrity,\n--> 225                        copy=copy, sort=sort)\n    226     return op.get_result()\n    227 \n",
      "C:\\Miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py in __init__(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy, sort)\n    257 \n    258         if len(objs) == 0:\n--> 259             raise ValueError('No objects to concatenate')\n    260 \n    261         if keys is None:\n",
      "ValueError: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# Read Dehradun and Geneva location data.\n",
    "\n",
    "# We will store some metadata about the stations as well.\n",
    "metadata = dict(locdata=list(), header=list())\n",
    "\n",
    "# We will only use the EPW file format for this exercise.\n",
    "file_type = 'epw'\n",
    "\n",
    "# I use os.path.join so the paths are automatically constructed based on the OS.\n",
    "path_epw_ddn = os.path.join('..', 'ddn', 'IND_UT_Dehradun.421110_ISHRAE2014.epw')\n",
    "\n",
    "# The small program get_weather stores data from the incoming weather\n",
    "# file as a dataframe.\n",
    "ddn, locdata, header = wf.get_weather('ddn', path_epw_ddn, file_type=file_type)\n",
    "\n",
    "# Save some metadata about the location.\n",
    "metadata['locdata'].append(locdata)\n",
    "metadata['header'].append(header)\n",
    "\n",
    "# Do the same with Geneva data. Except Geneva has multiple weather files, so use a loop.\n",
    "path_gen_folder = os.path.join('..', 'gen')\n",
    "list_genfiles = glob.glob(os.path.join(path_gen_folder, '*.{:s}'.format(file_type)))\n",
    "\n",
    "# Declare a list.\n",
    "gen = list()\n",
    "\n",
    "for file in list_genfiles:\n",
    "    \n",
    "    gen_temp, locdata, header = wf.get_weather('gen', file, file_type=file_type)\n",
    "    gen.append(gen_temp)\n",
    "    \n",
    "gen = pd.concat(gen)\n",
    "\n",
    "metadata['locdata'].append(locdata)\n",
    "metadata['header'].append(header)\n",
    "\n",
    "# Set the variable 'tmy' to the incoming data from Dehradun - so changing \n",
    "# this statement will allow you to run the worksheet with any location.\n",
    "tmy = ddn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DEHRADUN')\n",
    "\n",
    "print(ddn.describe())\n",
    "\n",
    "print('======\\r\\n')\n",
    "\n",
    "print('GENEVA')\n",
    "\n",
    "print(gen.describe())\n",
    "\n",
    "print('======')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Black Box Models </h2>\n",
    "\n",
    "For this exercise we will use the equation presented in Clarke (2001, Chpt. 7, sec. 7.1, pg. 206):\n",
    "\n",
    "$ E = a \\theta^2 + b R_d^2 + c R_f^2 + d V^2 + e \\theta + f R_d + g R_f + h V + i \\theta R_d + j \\theta R_f + k \\theta V + l R_d R_f + m R_d V + n R_f V + o, \\quad$  (1)\n",
    "\n",
    "where \"$E$ is the monthly energy requirement \\[kWh\\], $\\theta$ the monthly mean temperature \\[$^o$C\\], $R_d$ the monthly mean direct normal solar radiation \\[W/$m^2$\\], $R_f$ the monthly mean diffuse horizontal solar radiation \\[W/$m^2$\\], $V$ the montly mean wind speed [m/s], and 'a' through 'o' are the least squares coefficients\" (ibid).\n",
    "\n",
    "<b>NB</b>: The equation in the code is the same as this one, I've just rearranged the parameters and stated the constants as elements of an array rather than as separate variables. Also, I have omitted the bars over the variable names since the markdown rendering of bars and powers is awkward.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Exercises</h2>\n",
    "\n",
    "We will do two exercises in this workshop: \n",
    "\n",
    "<ol>\n",
    "<li> Fixed inputs, random coefficients: \n",
    "<li> Random inputs, fixed coefficients:\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate monthly energy use using the equation given in Clarke (2001).\n",
    "\n",
    "def E_month(theta, R_d, R_f, V, beta=np.random.rand(15,1)):\n",
    "\n",
    "    # By default, this function will use random coefficients to calculate the energy use. \n",
    "    # This is just for a demo since the coefficients are never \n",
    "    # going to be 'random', unless you have no idea what you are doing.\n",
    "            \n",
    "    e = beta[0] + beta[1]*theta + beta[2]*R_d + beta[3]*R_f + beta[4]*V + \\\n",
    "            beta[5]*theta**2 + beta[6]*R_d**2 + beta[7]*R_f**2 + beta[8]*V**2 + \\\n",
    "            beta[9]*theta*R_d + beta[10]*theta*R_f + beta[11]*theta*V + \\\n",
    "            beta[12]*R_d*R_f + beta[13]*R_d*V + beta[14]*R_f*V\n",
    "    \n",
    "    return e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random coefficients, fixed inputs\n",
    "\n",
    "For the first exercise, let's fix the inputs to typical values and use random coefficients to specify the relationship between inputs and output. \n",
    "\n",
    "The simulators you use will almost never be random - for buildings at least - so just treat this as an exercise. Imagine the building is changing, so its response to the weather inputs is changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monthly mean values of weather parameters for Dehradun.\n",
    "\n",
    "relevant_keys = ['tdb', 'dni', 'ghi', 'wspd']\n",
    "\n",
    "# Declare an empty dataframe.\n",
    "tmy_summary = pd.DataFrame()\n",
    "\n",
    "# Assign individual columns.\n",
    "# Each weather parameter is grouped by month, and the monthly mean calculated.\n",
    "tmy_summary['month'] = pd.unique(ddn['month'])\n",
    "tmy_summary.index = tmy_summary['month']\n",
    "\n",
    "for key in tmy.columns:\n",
    "    if key not in relevant_keys:\n",
    "        continue\n",
    "    tmy_summary[key] = tmy.groupby(by=['month'])[key].mean()\n",
    "\n",
    "# Calculate the monthly energy consumption with random coefficients.\n",
    "tmy_summary['energy'] = E_month(tmy_summary['tdb'], tmy_summary['dni'],\n",
    "                                       tmy_summary['ghi'], tmy_summary['wspd'])\n",
    "\n",
    "tmy_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do groupby manually using a for loop.\n",
    "\n",
    "# You don't need this - this is just a demo to show you how much easier your life is with pandas!\n",
    "\n",
    "tmy_summary2 = np.zeros_like(tmy_summary)\n",
    "\n",
    "for month in tmy_summary.index:\n",
    "    mask = ddn['month'] == month\n",
    "    tmy_summary2[month-1, tmy_summary.columns=='month'] = month\n",
    "    for key in tmy.columns:\n",
    "        if key not in relevant_keys:\n",
    "            continue\n",
    "        tmy_summary2[month-1, tmy_summary.columns==key] = np.mean(tmy.loc[mask, key])\n",
    "\n",
    "        # End inner for loop.\n",
    "# End outer for loop.    \n",
    "\n",
    "tmy_summary2 = pd.DataFrame(data=tmy_summary2,\n",
    "                            index=pd.unique(ddn['month']),\n",
    "                            columns=tmy_summary.columns)\n",
    "\n",
    "tmy_summary2['energy'] = E_month(tmy_summary2['tdb'], tmy_summary2['dni'],\n",
    "                                        tmy_summary2['ghi'], tmy_summary2['wspd'])\n",
    "\n",
    "print('The two dataframes should match, so most of the differences should be close to zero.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = tmy_summary2.values-tmy_summary.values\n",
    "print('Median = {0:4.3e}; Max. = {1:4.3e}; Min = {2:4.3e}.'.format(np.median(diffs), np.max(diffs), np.min(diffs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try smoothing instead of using a monthly average.\n",
    "\n",
    "def smoother(xin, lags):\n",
    "    \n",
    "    xout = np.zeros_like(xin)\n",
    "    \n",
    "    # Convert even numbers to odd.\n",
    "    if np.mod(lags, 2) == 0:\n",
    "        lags = lags + 1\n",
    "        \n",
    "    halfspan = int(np.floor(lags/2))\n",
    "        \n",
    "    for n, x in enumerate(xin):\n",
    "        \n",
    "        if (n < halfspan):\n",
    "            xout[n] = np.nanmean(xin[0:halfspan])\n",
    "        \n",
    "        elif (n > (xin.shape[0] - halfspan)):\n",
    "            xout[n] = np.nanmean(xin[-halfspan:-1])\n",
    "        \n",
    "        else:\n",
    "            lb = int(n - halfspan)\n",
    "            ub = int(n + halfspan)\n",
    "            xout[n] = np.nanmean(xin[lb:ub])\n",
    "        \n",
    "        # End IF statement.\n",
    "        \n",
    "    # End FOR loop.\n",
    "    \n",
    "    return xout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the smoothed data to calculate energy use but be aware that the original regression relationship was created with *monthly values*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "span = 720\n",
    "\n",
    "ddn_smooth = pd.DataFrame(data = np.zeros(tmy.shape), columns=tmy.columns, index=tmy.index)\n",
    "\n",
    "for key in tmy.columns:\n",
    "    if key not in relevant_keys:\n",
    "        continue\n",
    "    ddn_smooth[key] = smoother(ddn[key].values, span)\n",
    "    \n",
    "ddn_smooth['energy'] = E_month(ddn_smooth['tdb'], ddn_smooth['dni'],\n",
    "                                       ddn_smooth['ghi'], ddn_smooth['wspd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = np.arange(0, tmy.shape[0])\n",
    "# Find the index and value of the max temperature.\n",
    "ymax = np.max(ddn['tdb'].values)\n",
    "xmax = plot_x[ddn['tdb'].values==ymax]\n",
    "ymin = np.min(ddn['tdb'].values)\n",
    "xmin = plot_x[ddn['tdb'].values==ymin]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.plot(plot_x, ddn_smooth['tdb'].values, zorder=10, color=colours.blue)\n",
    "ax.plot(plot_x, ddn['tdb'].values, zorder = 1, color=colours.orange, alpha=0.5)\n",
    "ax.plot(plot_x, np.repeat(tmy_summary['tdb'], 8760/12), color=colours.blackest, zorder=11)\n",
    "plt.legend(['Hourly', 'Smoothed', 'Monthly'])\n",
    "plt.ylabel('Dry bulb temperature [$^o$C]')\n",
    "plt.xlabel('Hour of the year')\n",
    "plt.xlim(plot_x[0], plot_x[-1])\n",
    "plt.annotate('The hottest temperature \\n in the TMY file\\n',\n",
    "    xy=(xmax, ymax), arrowprops=dict(arrowstyle='->'), xytext=(4000, 10))\n",
    "plt.annotate('The coldest temperature \\n in the TMY file\\n',\n",
    "    xy=(xmin, ymin), arrowprops=dict(arrowstyle='->'), xytext=(4000, 5))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = range(0, tmy.shape[0])\n",
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.plot(plot_x, ddn_smooth['energy'], alpha=1, zorder=3, color=colours.blue)\n",
    "ax.plot(plot_x, np.repeat(tmy_summary['energy'], 8760/12), color=colours.blackest, zorder=10)\n",
    "plt.legend(['hourly', 'monthly'])\n",
    "plt.ylabel('Energy [kWh]')\n",
    "plt.xlabel('Hour of the year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the above exercise with data from Ahmedabad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparisons of weather from Dehradun and Ahmedabad.\n",
    "# Realise Dehradun is a far superior place to live than Ahmedabad. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.scatter(tmy_summary['tdb'], tmy_summary['energy'], color=colours.blue)\n",
    "plt.ylabel('Energy [kWh]')\n",
    "plt.xlabel('Temperature [$^o$C]')\n",
    "plt.title('Energy use vs Temperature')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.plot(range(0, tmy_summary.shape[0]), tmy_summary['energy'], color=colours.blue)\n",
    "plt.ylabel('Energy [kWh]')\n",
    "plt.xlabel('Month')\n",
    "plt.title('Energy use per month with random coefficients')\n",
    "plt.xticks(range(0, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed coefficients, random inputs\n",
    "\n",
    "Now let's try the same exercise with fixed coefficients and random inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Python module that can read these kinds of files.\n",
    "import h5py\n",
    "\n",
    "path_to_synw = os.path.join('..', 'gen', 'synthetic', 'syn_2051_2060.p')\n",
    "\n",
    "# The column names we expect to see in the synthetic files.\n",
    "column_names = ('year', 'month', 'day', 'hour', 'tdb', 'tdp', 'rh',\n",
    "                'ghi', 'dni', 'dhi', 'wspd', 'wdr')\n",
    "dc = 4  # No. of date columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a variable to point to the file.\n",
    "f = h5py.File(path_to_synw)\n",
    "# Specify an empty dataframe.\n",
    "syndata = pd.DataFrame()\n",
    "\n",
    "# Take each 'key' (variable) from the file and assign it to syndata.\n",
    "for key in f['syndata']:\n",
    "    syndata[key.lower()] = pd.Series(np.squeeze(np.array(f['syndata'][key])))\n",
    "\n",
    "f.close()\n",
    "\n",
    "# Number of years in dataset.\n",
    "n_years = np.unique(syndata['year']).size\n",
    "n_hours = 8760  # Fixed for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add wspd key.\n",
    "syndata['wspd'] = pd.Series(data=np.repeat(ddn['wspd'].values, n_years), index=syndata.index)\n",
    "syndata['wdr'] = pd.Series(data=np.repeat(ddn['wdr'].values, n_years), index=syndata.index)\n",
    "syndata['tdp'] = pd.Series(data=calc_tdp(syndata['tdb'].values, syndata['rh'].values), index=syndata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the date columns of this dataframe.\n",
    "# The columns should have been in this order already\n",
    "# but something was probably wrong in the reading/writing\n",
    "# or generation of the synthetic file.\n",
    "\n",
    "cols = syndata.columns.tolist()\n",
    "# print(ddn.columns)\n",
    "myorder = [3, 2, 0, 1, 8, 11, 7, 6, 5, 4, 9, 10]\n",
    "cols = [cols[i] for i in myorder]\n",
    "syndata = syndata[cols]\n",
    "print(syndata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fix the coefficients to some arbitrary values and plot inputs from  \n",
    "\n",
    "span = 720\n",
    "\n",
    "syn_smooth = pd.DataFrame(data = np.zeros(syndata.shape), columns=syndata.columns, index=syndata.index)\n",
    "\n",
    "for key in syndata.columns:\n",
    "    if key not in relevant_keys:\n",
    "        syn_smooth[key] = syndata[key].values\n",
    "    else:\n",
    "        syn_smooth[key] = smoother(syndata[key].values, span)\n",
    "    \n",
    "syn_smooth['energy'] = E_month(syn_smooth['tdb'], syn_smooth['dni'],\n",
    "                               syn_smooth['ghi'], syn_smooth['wspd'],\n",
    "                               beta=np.ones([15, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is generally not good practice to load modules after some code has been written.\n",
    "# If I were to write this as a program, I would shift these calls to the top.\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, n_hours)\n",
    "y = range(0, n_years)\n",
    "\n",
    "# Line plot.\n",
    "fig = plt.figure(figsize=(8, 6), facecolor='w', edgecolor='k')\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "X, Y = np.meshgrid(x,y)\n",
    "Z = syn_smooth['tdb'].values.reshape(-1, n_hours)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.cool,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_xlim(0, n_hours)\n",
    "ax.set_ylim(y[0], y[-1])\n",
    "ax.set_zlim(np.min(Z), np.max(Z))\n",
    "\n",
    "ax.set_ylabel('Year')\n",
    "ax.set_xlabel('Hours')\n",
    "ax.set_zlabel('Temperature [$^o$C]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, n_hours)\n",
    "y = range(0, n_years)\n",
    "\n",
    "# Line plot.\n",
    "fig = plt.figure(figsize=(8, 6), facecolor='w', edgecolor='k')\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "X, Y = np.meshgrid(x,y)\n",
    "Z = syn_smooth['energy'].values.reshape(-1, n_hours)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=cm.cool,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "ax.set_xlim(0, n_hours)\n",
    "ax.set_ylim(y[0], y[-1])\n",
    "ax.set_zlim(np.min(Z), np.max(Z))\n",
    "\n",
    "ax.set_ylabel('Year')\n",
    "ax.set_xlabel('Hours')\n",
    "ax.set_zlabel('Energy [kWh]')\n",
    "\n",
    "ax.set_zticks(np.arange(100000, 500000, 100000), )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(0, n_hours)\n",
    "y = range(0, n_years)\n",
    "\n",
    "# Line plot.\n",
    "fig = plt.figure(figsize=(8, 6), facecolor='w', edgecolor='k')\n",
    "ax = fig.gca()\n",
    "\n",
    "# X, Y = np.meshgrid(x,y)\n",
    "# z = syn_smooth['energy'].values.reshape(-1, n_hours)\n",
    "\n",
    "bp = sns.boxplot(x='month', y='energy', data=syn_smooth, palette='Set3')\n",
    "\n",
    "# ax.set_xlim(0, n_hours)\n",
    "# ax.set_ylim(y[0], y[-1])\n",
    "# ax.set_zlim(np.min(Z), np.max(Z))\n",
    "\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%4.0e'))\n",
    "ax.xaxis.set_major_formatter(FormatStrFormatter('%02d'))\n",
    "\n",
    "# ax.set_ylabel('Year')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Energy [kWh]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solar power with random weather inputs\n",
    "\n",
    "## Optional\n",
    "\n",
    "Use the `solar_power_func` to plot solar power production with random inputs. This function uses the procedure laid out in the iPython notebook: `solar_power`. \n",
    "\n",
    "I'm having trouble writing out the synthetic data to an EPW file for the `solar_power` function to read, but if you're interested we can talk about this.\n",
    "\n",
    "Bonus exercise: optimise tilt and/or orientation angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import solar_power_func as solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = solar.tmy_to_power(path_tmy_data=path_epw_ddn,\n",
    "                           surface_tilt=30, surface_azimuth=180,\n",
    "                           albedo=0.2, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = np.arange(0, tmy.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.plot(plot_x, power, zorder = 1, color=colours.orange, alpha=0.5)\n",
    "plt.ylabel('AC power [W]')\n",
    "plt.xlabel('Hour of the year')\n",
    "plt.xlim(plot_x[0], plot_x[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = syndata.iloc[0:n_hours, :].values\n",
    "fpath_out = os.path.join(\"..\", \"ddn\", \"ddn_syn.epw\")\n",
    "wf.give_weather(ts, locdata=locdata, stcode='ddn', header=header,\n",
    "                 masterfile=path_epw_ddn, ftype='epw',\n",
    "                 s_shift=0, fpath_out=fpath_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddn_syn, locdata_syn, header_syn, _ = wf.get_weather('ddn_syn', fpath_out, ftype='epw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_syn = solar.tmy_to_power(path_tmy_data=fpath_out,\n",
    "                           surface_tilt=30, surface_azimuth=180,\n",
    "                           albedo=0.2, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = np.arange(0, tmy.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[12,6])\n",
    "ax.plot(plot_x, power_syn, zorder = 1, color=colours.orange, alpha=0.5)\n",
    "plt.ylabel('AC power [W]')\n",
    "plt.xlabel('Hour of the year')\n",
    "plt.xlim(plot_x[0], plot_x[-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty analysis with EPlus\n",
    "\n",
    "### Steps/Notes\n",
    "\n",
    "1. Consider weather inputs from Indra.\n",
    "2. Run samples using EPlus - analyse results.\n",
    "    1. Either modify a base EPlus file using Eppy/scripting or in jePlus.\n",
    "    2. Or analyse the same EPlus file using many weather files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Bibliography </h2>\n",
    "\n",
    "<ul>\n",
    "<li>Rastogi, Parag. 2016. “On the Sensitivity of Buildings to Climate: The Interaction of Weather and Building Envelopes in Determining Future Building Energy Consumption.” PhD, Lausanne, Switzerland: Ecole polytechnique fédérale de Lausanne. EPFL Infoscience. https://infoscience.epfl.ch/record/220971?ln=en.\n",
    "<li>Rastogi, Parag, and Marilyne Andersen. 2015. “Embedding Stochasticity in Building Simulation Through Synthetic Weather Files.” In Proceedings of BS 2015. Hyderabad, India. http://infoscience.epfl.ch/record/208743.\n",
    "<li>———. 2016. “Incorporating Climate Change Predictions in the Analysis of Weather-Based Uncertainty.” In Proceedings of SimBuild 2016. Salt Lake City, UT, USA. http://infoscience.epfl.ch/record/208743.\n",
    "<li>Rastogi, Parag, Mohammad Emtiyaz Khan, and Marilyne Andersen. 2017. “Gaussian-Process-Based Emulators for Building Performance Simulation.” In Proceedings of BS 2017. San Francisco, CA, USA: IBPSA.\n",
    "<li>Iaccarino, Gianluca. 2008. “Quantification of Uncertainty in Flow Simulations Using Probabilistic Methods.” presented at the VKI Lecture Series, Stanford University, September. http://web.stanford.edu/group/uq/uq_youq.html.\n",
    "<li>Macdonald, Iain. 2002. “Quantifying the Effects of Uncertainty in Building Simulation.” Doctoral, University of Strathclyde. https://www.strath.ac.uk/media/departments/mechanicalengineering/esru/research/phdmphilprojects/macdonald_thesis.pdf.\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
